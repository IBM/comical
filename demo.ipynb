{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo notebook for COMICAL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, time, json\n",
    "from src.train_eval import train_eval\n",
    "from src.utils import plot_training_curves, plot_roc_curve, plot_precision_recall_curve, select_gpu\n",
    "from tabulate import tabulate\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.train import train\n",
    "from src.test import test_model\n",
    "from src.dataset_template import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fname_out_root = 'demo_run'\n",
    "path_data = 'data'\n",
    "top_n_perc = '0.5'\n",
    "paths = {\n",
    "    'path_mod_a' : os.path.join(os.getcwd(),path_data,'snp-encodings-from-vcf.csv'),\n",
    "    'path_mod_b' : os.path.join(os.getcwd(),path_data,'T1_struct_brainMRI_IDPs.csv'),\n",
    "    'path_pairs' : os.path.join(os.getcwd(),path_data,'pairs.csv'),\n",
    "    'path_mod_b_map' : os.path.join(os.getcwd(),path_data,'T1mri.csv'),\n",
    "    'path_res' : os.path.join(os.getcwd(),'results'),\n",
    "    'tensorboard_log': os.path.join(os.getcwd(),'results',fname_out_root,'tensorboard_logs'),\n",
    "    'wd' : os.getcwd(),\n",
    "    'path_target_labels' : os.path.join(os.getcwd(),path_data,'neuroDx.csv'),\n",
    "    'path_covariates' : os.path.join(os.getcwd(),path_data,'neuroDx_geneticPCs.csv'),\n",
    "    'path_mod_a2group_map' : os.path.join(os.getcwd(),path_data,'SNPs_and_disease_mapping_with_pvalues.csv'),\n",
    "    'path_mod_b2group_map' : os.path.join(os.getcwd(),path_data,'IDPs_and_disease_mapping.csv'),\n",
    "    'path_saved_pairs' : os.path.join(path_data,'pairs_top_n_'+top_n_perc+'.pickle'),\n",
    "    'path_data' : os.path.join(os.getcwd(),path_data),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values = {\n",
    "    'save_embeddings': '0',\n",
    "    'plot_embeddings': '0',\n",
    "    'top_n_perc': '0.5',\n",
    "    'resume_from_batch': '0',\n",
    "    'ckpt_name': 'None',\n",
    "    'downstream_pred_task_flag': '0',\n",
    "    'out_flag': 'pairs',\n",
    "    'target': 'PD',\n",
    "    'index_col': 'eid',\n",
    "    'feat_a_index_col': 'SNPs',\n",
    "    'feat_b_index_col': 'IDPs',\n",
    "    'feat_a_target_col': 'Disease',\n",
    "    'feat_b_target_col': 'Disease',\n",
    "    'coveriate_names': 'Age, Sex',\n",
    "    'count_bins': '64'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"batch_size\": '32768',\n",
    "    'save_embeddings': '0',\n",
    "    'plot_embeddings': '0',\n",
    "    'top_n_perc': '0.5',\n",
    "    'resume_from_batch': '0',\n",
    "    'ckpt_name': 'None',\n",
    "    'downstream_pred_task_flag': '0',\n",
    "    'out_flag': 'pairs',\n",
    "    'target': 'PD',\n",
    "    'index_col': 'eid',\n",
    "    'feat_a_index_col': 'SNPs',\n",
    "    'feat_b_index_col': 'IDPs',\n",
    "    'feat_a_target_col': 'Disease',\n",
    "    'feat_b_target_col': 'Disease',\n",
    "    'coveriate_names': 'Age, Sex',\n",
    "    'count_bins': '64'\n",
    "    'ckpt_name': args.ckpt_name,\n",
    "    'covariates_names': list(args.coveriate_names),\n",
    "    'dim_feedforward': int(args.dim_feedforward),\n",
    "    'target': args.target,\n",
    "    'd_model': int(args.d_model),\n",
    "    'dropout': float(args.dropout),\n",
    "    'epochs': int(args.epochs),\n",
    "    'feat_a_index_col':args.feat_a_index_col,\n",
    "    'feat_b_index_col':args.feat_b_index_col,\n",
    "    'feat_a_target_col':args.feat_a_target_col,\n",
    "    'feat_b_target_col':args.feat_b_target_col,\n",
    "    'fname_root_out': args.fname_out_root,\n",
    "    'gpus_per_trial': args.gpus_per_trial,\n",
    "    'index_col': args.index_col if type(args.index_col) == str else int(args.index_col),\n",
    "    'learning_rate': float(args.learning_rate),\n",
    "    'nhead': int(args.nhead),\n",
    "    'num_layers': int(args.num_layers),\n",
    "    'out_flag': args.out_flag,\n",
    "    'pairs_exist': pairs_exist,\n",
    "    'plot_embeddings': bool(int(args.plot_embeddings)),\n",
    "    'rnd_st': int(args.random_seed),\n",
    "    'resume_from_batch': bool(int(args.resume_from_batch)),\n",
    "    'save_embeddings': bool(int(args.save_embeddings)),\n",
    "    'downstream_pred_task_flag': bool(int(args.downstream_pred_task_flag)),\n",
    "    'test_size': float(int(args.test_size) / 100),\n",
    "    'top_n_perc': float(args.top_n_perc),\n",
    "    'tune_flag': bool(int(args.tune_flag)),\n",
    "    'units': int(args.units),\n",
    "    'val_size': float(int(args.val_size) / 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create dataset object\n",
    "data = dataset(paths, args)\n",
    "\n",
    "# Get data splits and confirm there is no overlap between them.\n",
    "train_idx, val_idx, test_idx = data.get_data_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train_index' : train_idx,\n",
    "    'val_index' : val_idx,\n",
    "    'test_index' : test_idx,\n",
    "    \"random_seed\": '42',\n",
    "    \"val_size\": '20',\n",
    "    \"test_size\": '10',\n",
    "    \"gpu_nums\": '7',\n",
    "    \"tune_flag\": '0',\n",
    "    \"gpus_per_trial\": '1',\n",
    "    \"batch_size\": '32768',\n",
    "    \"lr\": '0.01',\n",
    "    \"epochs\": '2',\n",
    "    \"num_layers\": '2',\n",
    "    \"d_model\": '64',\n",
    "    \"nhead\": '4',\n",
    "    \"dim_feedforward\": '32',\n",
    "    \"dropout\": '0.0',\n",
    "    \"units\": '16',\n",
    "    'tune': False,\n",
    "    'tensorboard_log_path':paths['tensorboard_log'],\n",
    "    'num_snps':10000,\n",
    "    'num_idps':139,\n",
    "    'idp_tok_dims':64,\n",
    "    'save_embeddings':False,\n",
    "    'plot_embeddings':False,\n",
    "    'results_path':os.path.join(os.getcwd(),'results',fname_out_root),\n",
    "    'resume_from_batch':args['resume_from_batch'],\n",
    "    'ckpt_name':args['ckpt_name'],\n",
    "    'subject_based_pred_flag':args['downstream_pred_task_flag'],\n",
    "    'out_flag':args['out_flag'],\n",
    "    'target':args['target'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args = {\n",
    "    'batch_size': int(args.batch_size),\n",
    "    'ckpt_name': args.ckpt_name,\n",
    "    'count_bins': int(args.count_bins),\n",
    "    'covariates_names': list(args.coveriate_names),\n",
    "    'dim_feedforward': int(args.dim_feedforward),\n",
    "    'target': args.target,\n",
    "    'd_model': int(args.d_model),\n",
    "    'dropout': float(args.dropout),\n",
    "    'epochs': int(args.epochs),\n",
    "    'feat_a_index_col':args.feat_a_index_col,\n",
    "    'feat_b_index_col':args.feat_b_index_col,\n",
    "    'feat_a_target_col':args.feat_a_target_col,\n",
    "    'feat_b_target_col':args.feat_b_target_col,\n",
    "    'fname_root_out': fname_out_root,\n",
    "    'gpus_per_trial': args.gpus_per_trial,\n",
    "    'index_col': args.index_col if type(args.index_col) == str else int(args.index_col),\n",
    "    'learning_rate': float(args.learning_rate),\n",
    "    'nhead': int(args.nhead),\n",
    "    'num_layers': int(args.num_layers),\n",
    "    'out_flag': args.out_flag,\n",
    "    'pairs_exist': pairs_exist,\n",
    "    'plot_embeddings': bool(int(args.plot_embeddings)),\n",
    "    'rnd_st': int(args.random_seed),\n",
    "    'resume_from_batch': bool(int(args.resume_from_batch)),\n",
    "    'save_embeddings': bool(int(args.save_embeddings)),\n",
    "    'downstream_pred_task_flag': bool(int(args.downstream_pred_task_flag)),\n",
    "    'test_size': float(int(args.test_size) / 100),\n",
    "    'top_n_perc': float(args.top_n_perc),\n",
    "    'tune_flag': bool(int(args.tune_flag)),\n",
    "    'units': int(args.units),\n",
    "    'val_size': float(int(args.val_size) / 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train model ###\n",
    "train_losses, val_losses = train(config, data=data, checkpoint_dir = paths['checkpoint_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate model ##\n",
    "# Select checkpoint with the lowest loss on validation set\n",
    "best_epoch = np.argmin(val_losses)\n",
    "best_checkpoint_path = os.path.join(paths['checkpoint_name'], f'checkpoint_epoch_{best_epoch}')\n",
    "\n",
    "# Evaluate on test set - using best checkpointed model\n",
    "loss_test, acc_test, _ = test_model(config, args ,data, test_idx, best_checkpoint_path)\n",
    "\n",
    "# Return dictionary with results, data info\n",
    "results_dict = {\n",
    "    'metrics':{\n",
    "        'loss_test':loss_test,\n",
    "        'acc_test':acc_test,\n",
    "    },\n",
    "    'data':{\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses':val_losses,\n",
    "    },\n",
    "    'hyperparams':{\n",
    "        'lr':config[\"lr\"],\n",
    "        'batch_size':config[\"batch_size\"],\n",
    "        'units':config[\"units\"],\n",
    "        'd_model':config[\"d_model\"],\n",
    "        'nhead':config[\"nhead\"],\n",
    "        'dim_feedforward':config[\"dim_feedforward\"],\n",
    "        'dropout':config[\"dropout\"],\n",
    "        'layer_norm_eps':config[\"layer_norm_eps\"],\n",
    "        'activation':config[\"activation\"],\n",
    "        'checkpoint_path':best_checkpoint_path\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(f'Saving results dictionary in {os.path.join(os.getcwd(),\"results\",fname_out_root,\"result_dict.json\")}')\n",
    "    with open(os.path.join(os.getcwd(),'results',fname_out_root,'result_dict.json'), \"w\") as outfile:\n",
    "        json.dump(results_dict, outfile)\n",
    "    \n",
    "    print(f'Test set loss {results_dict[\"metrics\"][\"loss_test\"]}')\n",
    "    print(f'Test set top-1 accuracy {results_dict[\"metrics\"][\"acc_test\"]}')\n",
    "\n",
    "    # Plot losses and result curves\n",
    "    plot_training_curves(results_dict['data']['train_losses'], results_dict['data']['val_losses'], os.path.join(os.getcwd(),'results',fname_out_root,'training_curves.pdf'))\n",
    "    if args.out_flag == 'clf':\n",
    "        plot_roc_curve(results_dict['data']['test_preds'], results_dict['data']['test_labels'], os.path.join(os.getcwd(),'results',fname_out_root,'roc_curve.pdf'))\n",
    "        plot_precision_recall_curve(results_dict['data']['test_preds'], results_dict['data']['test_labels'], os.path.join(os.getcwd(),'results',fname_out_root,'precision_recall_curve.pdf'))\n",
    "\n",
    "    # Print hyperparameter configuration and results metrics\n",
    "    print(\"Hyperparameter configuration and results metrics:\")\n",
    "    table_data = []\n",
    "    # Add hyperparameter configuration to table data\n",
    "    for key, value in results_dict['hyperparams'].items():\n",
    "        table_data.append([key, value])\n",
    "\n",
    "    # Add results metrics to table data\n",
    "    for key, value in results_dict['metrics'].items():\n",
    "        table_data.append([key, value])\n",
    "\n",
    "    table = tabulate(table_data, headers=[\"Parameter\", \"Value\"], tablefmt=\"grid\")\n",
    "\n",
    "    # Save table to txt file and print out\n",
    "    with open(os.path.join(os.getcwd(),'results',fname_out_root,'results_and_config_out.txt'), \"w\") as outfile:\n",
    "        outfile.write(table)\n",
    "    print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comical-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
